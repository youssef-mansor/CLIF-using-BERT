{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9bdaee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "# from transformers import MarianMTModel, MarianTokenizer\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, AutoModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03e064d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is the capital of Argentina?',\n",
       " 'Who won the Nobel Prize for Literature in 2020?',\n",
       " 'What is the square root of 144?',\n",
       " 'How far is the moon from the Earth?',\n",
       " 'Who painted the Mona Lisa?']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('English_queries.txt', 'r') as file:\n",
    "    queries_en = [line.strip() for line in file.readlines()]\n",
    "    \n",
    "# Print First 5 queries out of the 142 queries\n",
    "queries_en[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e7f8af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Arjantin'in başkenti Buenos Aires'tir.\",\n",
       " \"2020 yılında Edebiyat Nobel Ödülü'nü Amerikalı şair Louise Glück kazanmıştır.\",\n",
       " \"144'ün karekökü 12'dir.\",\n",
       " \"Ay, Dünya'dan ortalama 384.400 kilometre uzaklıktadır.\",\n",
       " 'Mona Lisa tablosu, İtalyan Rönesans sanatçısı Leonardo da Vinci tarafından resmedilmiştir.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('Turkish_doc.txt', 'r') as file:\n",
    "    doc_tr = [line.strip() for line in file.readlines()]\n",
    "    \n",
    "# Print First 5 queries out of the 142 queries\n",
    "doc_tr[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4dc4a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizing using TfidVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "vecs_en = vectorizer.fit_transform(queries_en)\n",
    "vecs_tr = vectorizer.fit_transform(doc_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23e96d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing truncated SVD\n",
    "svd = TruncatedSVD(n_components=2)\n",
    "lsi_en = svd.fit_transform(vecs_en)\n",
    "lsi_tr = svd.fit_transform(vecs_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "583b90ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine similarity between files\n",
    "def cosine_sim(a, b):\n",
    "    dot_product = np.dot(a, b)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    return dot_product / (norm_a * norm_b)\n",
    "\n",
    "# Jaccard similarity between files\n",
    "def jaccard_sim(a, b):\n",
    "    intersection = len(set(a).intersection(set(b)))\n",
    "    union = len(set(a).union(set(b)))\n",
    "    return intersection / union\n",
    "\n",
    "# Dice similarity between files\n",
    "def dice_sim(a, b):\n",
    "    intersection = len(set(a).intersection(set(b)))\n",
    "    total = len(a) + len(b)\n",
    "    return (2 * intersection) / total\n",
    "\n",
    "# Overlap similarity between files\n",
    "def overlap_sim(a, b):\n",
    "    intersection = len(set(a).intersection(set(b)))\n",
    "    min_len = min(len(a), len(b))\n",
    "    return intersection / min_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a091b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the similarity matrix between the English and Turkish files using different similarity measures\n",
    "sim_cosine = np.zeros((len(queries_en), len(doc_tr)))\n",
    "sim_jaccard = np.zeros((len(queries_en), len(doc_tr)))\n",
    "sim_dice = np.zeros((len(queries_en), len(doc_tr)))\n",
    "sim_overlap = np.zeros((len(queries_en), len(doc_tr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "915fcc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity:\n",
      " [[ 0.86193947 -0.41642314  0.87596189 ...  0.90901999  0.87163871\n",
      "  -0.13050392]\n",
      " [ 0.40993705  0.94917912  0.38392324 ...  0.31508027  0.39211715\n",
      "   0.99976784]\n",
      " [ 0.97936306 -0.10113143  0.98469743 ...  0.99483637  0.98310916\n",
      "   0.19604765]\n",
      " ...\n",
      " [ 0.90206479  0.52138446  0.88947098 ...  0.85351074  0.89349867\n",
      "   0.74936523]\n",
      " [ 0.95240032 -0.20608755  0.96065719 ...  0.97845882  0.95815003\n",
      "   0.09092957]\n",
      " [ 0.86392265  0.58914089  0.84930302 ...  0.80824373  0.85396275\n",
      "   0.80079749]]\n",
      "Jaccard similarity:\n",
      " [[0.09090909 0.07692308 0.11111111 ... 0.0625     0.08333333 0.07692308]\n",
      " [0.08333333 0.07142857 0.1        ... 0.05882353 0.07692308 0.07142857]\n",
      " [0.1        0.08333333 0.125      ... 0.06666667 0.09090909 0.08333333]\n",
      " ...\n",
      " [0.08333333 0.07142857 0.1        ... 0.05882353 0.07692308 0.07142857]\n",
      " [0.08333333 0.07142857 0.1        ... 0.05882353 0.07692308 0.07142857]\n",
      " [0.08333333 0.07142857 0.1        ... 0.05882353 0.07692308 0.07142857]]\n",
      "Dice similarity:\n",
      " [[0.00235294 0.00235294 0.00235294 ... 0.00235294 0.00235294 0.00235294]\n",
      " [0.00235294 0.00235294 0.00235294 ... 0.00235294 0.00235294 0.00235294]\n",
      " [0.00235294 0.00235294 0.00235294 ... 0.00235294 0.00235294 0.00235294]\n",
      " ...\n",
      " [0.00235294 0.00235294 0.00235294 ... 0.00235294 0.00235294 0.00235294]\n",
      " [0.00235294 0.00235294 0.00235294 ... 0.00235294 0.00235294 0.00235294]\n",
      " [0.00235294 0.00235294 0.00235294 ... 0.00235294 0.00235294 0.00235294]]\n",
      "Overlap similarity:\n",
      " [[0.00392157 0.00392157 0.00392157 ... 0.00392157 0.00392157 0.00392157]\n",
      " [0.00392157 0.00392157 0.00392157 ... 0.00392157 0.00392157 0.00392157]\n",
      " [0.00392157 0.00392157 0.00392157 ... 0.00392157 0.00392157 0.00392157]\n",
      " ...\n",
      " [0.00392157 0.00392157 0.00392157 ... 0.00392157 0.00392157 0.00392157]\n",
      " [0.00392157 0.00392157 0.00392157 ... 0.00392157 0.00392157 0.00392157]\n",
      " [0.00392157 0.00392157 0.00392157 ... 0.00392157 0.00392157 0.00392157]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(queries_en)):\n",
    "    for j in range(len(doc_tr)):\n",
    "        sim_cosine[i][j] = cosine_sim(lsi_en[i], lsi_tr[j])\n",
    "        sim_jaccard[i][j] = jaccard_sim(vecs_en[i].toarray()[0], vecs_tr[j].toarray()[0])\n",
    "        sim_dice[i][j] = dice_sim(vecs_en[i].toarray()[0], vecs_tr[j].toarray()[0])\n",
    "        sim_overlap[i][j] = overlap_sim(vecs_en[i].toarray()[0], vecs_tr[j].toarray()[0])\n",
    "\n",
    "# Print the similarity matrices\n",
    "print(\"Cosine similarity:\\n\", sim_cosine)\n",
    "print(\"Jaccard similarity:\\n\", sim_jaccard)\n",
    "print(\"Dice similarity:\\n\", sim_dice)\n",
    "print(\"Overlap similarity:\\n\", sim_overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e5bc211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for cosine similarity: 0.007042253521126761\n",
      "Accuracy for Jaccard similarity: 0.007042253521126761\n",
      "Accuracy for Dice similarity: 0.007042253521126761\n",
      "Accuracy for overlap similarity: 0.007042253521126761\n"
     ]
    }
   ],
   "source": [
    "cosine_correct = 0\n",
    "jaccard_correct = 0\n",
    "dice_correct = 0\n",
    "overlap_correct = 0\n",
    "\n",
    "for i in range(len(queries_en)):\n",
    "  cosine_max_index = np.argmax(sim_cosine[i])\n",
    "  jaccard_max_index = np.argmax(sim_jaccard[i])\n",
    "  dice_max_index = np.argmax(sim_dice[i])\n",
    "  overlap_max_index = np.argmax(sim_overlap[i])\n",
    "  if cosine_max_index == i:\n",
    "    cosine_correct += 1\n",
    "  if jaccard_max_index == i:\n",
    "      jaccard_correct += 1\n",
    "  if dice_max_index == i:\n",
    "      dice_correct += 1\n",
    "  if overlap_max_index == i:\n",
    "      overlap_correct += 1\n",
    "\n",
    "cosine_accuracy = cosine_correct / len(queries_en)\n",
    "jaccard_accuracy = jaccard_correct / len(queries_en)\n",
    "dice_accuracy = dice_correct / len(queries_en)\n",
    "overlap_accuracy = overlap_correct / len(queries_en)\n",
    "\n",
    "print(f\"\\nAccuracy for cosine similarity: {cosine_accuracy}\")\n",
    "print(f\"Accuracy for Jaccard similarity: {jaccard_accuracy}\")\n",
    "print(f\"Accuracy for Dice similarity: {dice_accuracy}\")\n",
    "print(f\"Accuracy for overlap similarity: {overlap_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f825ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for Average Similarity: 0.014084507042253521\n"
     ]
    }
   ],
   "source": [
    "avg_sim_sim = sim_cosine + sim_jaccard + sim_dice + sim_overlap\n",
    "avg_sim_correct = 0\n",
    "for i in range(len(queries_en)):\n",
    "  avg_sim_max_index = np.argmax(avg_sim_sim[i])\n",
    "  if avg_sim_max_index == i:\n",
    "    avg_sim_correct += 1\n",
    "\n",
    "avg_sim_accuracy = avg_sim_correct / len(queries_en)\n",
    "print(f\"\\nAccuracy for Average Similarity: {avg_sim_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e00f877f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/youssef/anaconda3/envs/d2l/lib/python3.9/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
      "/home/youssef/anaconda3/envs/d2l/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/home/youssef/anaconda3/envs/d2l/lib/python3.9/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "# Define the language model and tokenizer for translation\n",
    "model_name = \"Helsinki-NLP/opus-mt-tc-big-en-tr\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7b734ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: Hello, how are you? I was wondering if you could lend me a pen\n",
      "Turkish: Merhaba, nasılsınız? Acaba bana bir kalem ödünç verebilir misiniz?\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "def translate_en_to_tr(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True)\n",
    "    translated = model.generate(**inputs)\n",
    "    return tokenizer.decode(translated[0], skip_special_tokens=True)\n",
    "\n",
    "# Example usage\n",
    "english_text = \"Hello, how are you? I was wondering if you could lend me a pen\"\n",
    "turkish_text = translate_en_to_tr(english_text)\n",
    "print(f\"English: {english_text}\")\n",
    "print(f\"Turkish: {turkish_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24813f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tranrslate the queries to Turkish\n",
    "queries_tr = []\n",
    "for query in queries_en:\n",
    "    input_ids = tokenizer.encode(query, return_tensors='pt')\n",
    "    translated = model.generate(input_ids=input_ids, num_beams=4, max_length=100, early_stopping=True)\n",
    "    translated_query = tokenizer.decode(translated[0], skip_special_tokens=True)\n",
    "    queries_tr.append(translated_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "428ad393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Arjantin'in başkenti neresidir?\",\n",
       " \"2020 yılında Nobel Edebiyat Ödülü'nü kim kazandı?\",\n",
       " \"144'ün karekökü nedir?\",\n",
       " \"Ay, Dünya'dan ne kadar uzakta?\",\n",
       " \"Mona Lisa'yı kim boyadı?\"]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print First 5 queries of 142\n",
    "queries_tr[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0eb3c633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the documents using the TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "vecs_trans = vectorizer.fit_transform(queries_tr)\n",
    "vecs_tr = vectorizer.fit_transform(doc_tr)\n",
    "\n",
    "# Compute the truncated SVD\n",
    "svd = TruncatedSVD(n_components=2)\n",
    "lsi_en = svd.fit_transform(vecs_trans)\n",
    "lsi_tr = svd.fit_transform(vecs_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a715f3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity:\n",
      " [[ 0.92005173 -0.30336921  0.92444005 ...  0.94801012  0.93634426\n",
      "  -0.0154039 ]\n",
      " [ 0.43275223  0.93827543  0.42249056 ...  0.3605264   0.39281196\n",
      "   0.99817864]\n",
      " [ 0.38992982  0.9534865   0.37945145 ...  0.31631652  0.34918318\n",
      "   0.99991054]\n",
      " ...\n",
      " [ 0.27556667  0.98296901  0.26463664 ...  0.19912787  0.23315714\n",
      "   0.99417365]\n",
      " [ 0.78434825  0.69146056  0.77725596 ...  0.73314398  0.75639795\n",
      "   0.87055589]\n",
      " [ 0.25616064  0.98646908  0.2451711  ...  0.17936107  0.21353511\n",
      "   0.99180243]]\n",
      "Jaccard similarity:\n",
      " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.0625    ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.07692308 0.         0.         ... 0.0625     0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "Dice similarity:\n",
      " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.11764706]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.14285714 0.         0.         ... 0.11764706 0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "Overlap similarity:\n",
      " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.125     ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.16666667 0.         0.         ... 0.125      0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Compute the similarity matrix between the English and Spanish documents using different similarity measures\n",
    "n = len(queries_en)\n",
    "m = len(doc_tr)\n",
    "sim_cosine = np.zeros((n, m))\n",
    "sim_jaccard = np.zeros((n, m))\n",
    "sim_dice = np.zeros((n, m))\n",
    "sim_overlap = np.zeros((n, m))\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(m):\n",
    "        sim_cosine[i][j] = cosine_sim(lsi_en[i], lsi_tr[j])\n",
    "        sim_jaccard[i][j] = jaccard_sim(set(vecs_tr[j].nonzero()[1]), set(vecs_trans[i].nonzero()[1]))\n",
    "        sim_dice[i][j] = dice_sim(set(vecs_tr[j].nonzero()[1]), set(vecs_trans[i].nonzero()[1]))\n",
    "        sim_overlap[i][j] = overlap_sim(set(vecs_tr[j].nonzero()[1]), set(vecs_trans[i].nonzero()[1]))\n",
    "\n",
    "# Print the similarity matrices\n",
    "print(\"Cosine similarity:\\n\", sim_cosine)\n",
    "print(\"Jaccard similarity:\\n\", sim_jaccard)\n",
    "print(\"Dice similarity:\\n\", sim_dice)\n",
    "print(\"Overlap similarity:\\n\", sim_overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb61f8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for cosine similarity: 0.0\n",
      "Accuracy for Jaccard similarity: 0.0\n",
      "Accuracy for Dice similarity: 0.0\n",
      "Accuracy for overlap similarity: 0.0\n"
     ]
    }
   ],
   "source": [
    "cosine_correct = 0\n",
    "jaccard_correct = 0\n",
    "dice_correct = 0\n",
    "overlap_correct = 0\n",
    "\n",
    "for i in range(n):\n",
    "  cosine_max_index = np.argmax(sim_cosine[i])\n",
    "  jaccard_max_index = np.argmax(sim_jaccard[i])\n",
    "  dice_max_index = np.argmax(sim_dice[i])\n",
    "  overlap_max_index = np.argmax(sim_overlap[i])\n",
    "  if cosine_max_index == i:\n",
    "    cosine_correct += 1\n",
    "  if jaccard_max_index == i:\n",
    "      jaccard_correct += 1\n",
    "  if dice_max_index == i:\n",
    "      dice_correct += 1\n",
    "  if overlap_max_index == i:\n",
    "      overlap_correct += 1\n",
    "\n",
    "cosine_accuracy = cosine_correct / n\n",
    "jaccard_accuracy = jaccard_correct / n\n",
    "dice_accuracy = dice_correct / n\n",
    "overlap_accuracy = overlap_correct / n\n",
    "\n",
    "print(f\"\\nAccuracy for cosine similarity: {cosine_accuracy}\")\n",
    "print(f\"Accuracy for Jaccard similarity: {jaccard_accuracy}\")\n",
    "print(f\"Accuracy for Dice similarity: {dice_accuracy}\")\n",
    "print(f\"Accuracy for overlap similarity: {overlap_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01e5187f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for Average Similarity: 0.0\n"
     ]
    }
   ],
   "source": [
    "avg_sim_sim = sim_cosine + sim_jaccard + sim_dice + sim_overlap\n",
    "avg_sim_correct = 0\n",
    "for i in range(n):\n",
    "  avg_sim_max_index = np.argmax(avg_sim_sim[i])\n",
    "  if avg_sim_max_index == i:\n",
    "    avg_sim_correct += 1\n",
    "\n",
    "avg_sim_accuracy = avg_sim_correct / n\n",
    "print(f\"\\nAccuracy for Average Similarity: {avg_sim_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8f08686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba5d21950d904cfaaa7da1bd532afc8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da7c6d12e2524f8f880d892cfa4ed242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce5dc5565a3d4947969117bf082e7c62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63485bd2be5847f7832061157e50b785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4444bea747a9448c97579b22d7a49dd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/youssef/anaconda3/envs/d2l/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "# Load the multilingual BERT model and tokenizer\n",
    "model = AutoModel.from_pretrained('bert-base-multilingual-cased')\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "757bb416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is the capital of Argentina?',\n",
       " 'Who won the Nobel Prize for Literature in 2020?',\n",
       " 'What is the square root of 144?',\n",
       " 'How far is the moon from the Earth?',\n",
       " 'Who painted the Mona Lisa?']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('English_queries.txt', 'r') as file:\n",
    "    queries_en = [line.strip() for line in file.readlines()]\n",
    "    \n",
    "# Print First 5 queries out of the 142 queries\n",
    "queries_en[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff810831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Arjantin'in başkenti Buenos Aires'tir.\",\n",
       " \"2020 yılında Edebiyat Nobel Ödülü'nü Amerikalı şair Louise Glück kazanmıştır.\",\n",
       " \"144'ün karekökü 12'dir.\",\n",
       " \"Ay, Dünya'dan ortalama 384.400 kilometre uzaklıktadır.\",\n",
       " 'Mona Lisa tablosu, İtalyan Rönesans sanatçısı Leonardo da Vinci tarafından resmedilmiştir.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('Turkish_doc.txt', 'r') as file:\n",
    "    doc_tr = [line.strip() for line in file.readlines()]\n",
    "    \n",
    "# Print First 5 queries out of the 142 queries\n",
    "doc_tr[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4538d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "d2l"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
